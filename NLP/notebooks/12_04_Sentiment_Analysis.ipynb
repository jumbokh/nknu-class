{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mm4D1f4MOGWd"
   },
   "source": [
    "# 情緒分析(Sentiment Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Y0JGbuboOGWf"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Activation, Dense, Embedding, LSTM, Bidirectional\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EeYKm5SeOGWi"
   },
   "source": [
    "## 資料前置處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kdnuggets.com/2020/03/tensorflow-keras-tokenization-text-data-prep.html\n",
    "num_words = 1000\n",
    "oov_token = '<UNK>'\n",
    "pad_type = 'post'\n",
    "trunc_type = 'post'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word index:\n",
      " 2222\n",
      "\n",
      "Padded training sequences:\n",
      " [[  3   8   7 ...   0   0   0]\n",
      " [ 57  15   3 ...   0   0   0]\n",
      " [  2 109   3 ...   0   0   0]\n",
      " ...\n",
      " [ 29   2 290 ...   0   0   0]\n",
      " [ 85  10  11 ...   0   0   0]\n",
      " [ 81   4  10 ...   0   0   0]]\n",
      "\n",
      "Padded training shape: (7086, 40)\n",
      "Training sequences data type: <class 'list'>\n",
      "Padded Training sequences data type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# 將訓練資料轉成索引\n",
    "# 讀檔\n",
    "with open('./data/Sentiment_data.txt','r+', encoding='UTF-8') as f:\n",
    "    train_data = f.readlines()\n",
    "\n",
    "# 取得標註(y)、語句(x)\n",
    "x=[]\n",
    "y=[]\n",
    "for line in train_data:\n",
    "    label, sentence = line.strip().split(\"\\t\")\n",
    "    x.append(sentence)\n",
    "    y.append(int(label))\n",
    "\n",
    "# 分詞    \n",
    "tokenizer = Tokenizer(num_words=num_words, oov_token=oov_token)\n",
    "tokenizer.fit_on_texts(x)\n",
    "\n",
    "# 取得單字與索引對照表\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Encode training data sentences into sequences\n",
    "train_sequences = tokenizer.texts_to_sequences(x)\n",
    "\n",
    "# 計算訓練資料的字句最大字數\n",
    "maxlen = max([len(i) for i in train_sequences])\n",
    "\n",
    "# 補 0\n",
    "train_padded = pad_sequences(train_sequences, padding=pad_type, truncating=trunc_type, maxlen=maxlen)\n",
    "\n",
    "# Output the results of our work\n",
    "print(\"Word index:\\n\", len(word_index.keys()))\n",
    "# print(\"\\nTraining sequences:\\n\", train_sequences)\n",
    "print(\"\\nPadded training sequences:\\n\", train_padded)\n",
    "print(\"\\nPadded training shape:\", train_padded.shape)\n",
    "print(\"Training sequences data type:\", type(train_sequences))\n",
    "print(\"Padded Training sequences data type:\", type(train_padded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 10,  11,  13,  78,  71,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0],\n",
       "       [100, 206,  51,  10,  11,  52,  13,   3, 108,  64,  21,   2,  90,\n",
       "        121, 128,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0],\n",
       "       [ 83, 285,  58, 286,  30, 287, 153, 205,  20,  30, 213,   4,  83,\n",
       "        288,  99,  30,  35,  10,  11, 204, 214,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0],\n",
       "       [ 30, 289,  82,  35,  91,  10,  11,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0],\n",
       "       [ 81,   4,  10,  11,  13,  14,  79,  21,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0],\n",
       "       [ 10,  11,  15, 136,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0],\n",
       "       [ 28,  10,  11,  15,  33,  64,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0],\n",
       "       [ 29,   2, 290,  87, 140,   3, 291,  21, 207,   2,  48, 292,  32,\n",
       "         62,  31,   2, 293,   3,  21,  10,  11,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0],\n",
       "       [ 85,  10,  11,  13, 130,  14,  71,  21,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0],\n",
       "       [ 81,   4,  10,  11,  15,  14,  79,  21,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_padded[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EeYKm5SeOGWi"
   },
   "source": [
    "## 建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "bE9XiUGbOGWi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 128)         284416    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, None, 128)         98816     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 482,177\n",
      "Trainable params: 482,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 可輸入不定長度的整數陣列\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "\n",
    "x = Embedding(len(word_index.keys()), 128)(inputs)\n",
    "# 使用 2 個 bidirectional LSTM\n",
    "x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "x = Bidirectional(LSTM(64))(x)\n",
    "# 分類\n",
    "outputs = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pTWUs_XUOGWn"
   },
   "source": [
    "## 訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(train_padded, np.array(y), test_size=0.2, random_state=42)\n",
    "type(Xtrain), type(ytrain[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "89/89 [==============================] - 1s 15ms/step - loss: 0.2737 - accuracy: 0.8553 0s - loss: 0.3533 - ac\n",
      "Epoch 2/10\n",
      "89/89 [==============================] - 1s 15ms/step - loss: 0.0315 - accuracy: 0.9915\n",
      "Epoch 3/10\n",
      "89/89 [==============================] - 1s 15ms/step - loss: 0.0117 - accuracy: 0.9963\n",
      "Epoch 4/10\n",
      "89/89 [==============================] - 1s 15ms/step - loss: 0.0060 - accuracy: 0.9977\n",
      "Epoch 5/10\n",
      "89/89 [==============================] - 1s 15ms/step - loss: 0.0024 - accuracy: 0.9989\n",
      "Epoch 6/10\n",
      "89/89 [==============================] - 1s 15ms/step - loss: 0.0037 - accuracy: 0.9986\n",
      "Epoch 7/10\n",
      "89/89 [==============================] - 1s 15ms/step - loss: 9.8275e-04 - accuracy: 0.9995\n",
      "Epoch 8/10\n",
      "89/89 [==============================] - 1s 15ms/step - loss: 0.0036 - accuracy: 0.9986\n",
      "Epoch 9/10\n",
      "89/89 [==============================] - 1s 15ms/step - loss: 0.0116 - accuracy: 0.9974\n",
      "Epoch 10/10\n",
      "89/89 [==============================] - 1s 15ms/step - loss: 0.0108 - accuracy: 0.9963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e084744d00>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "model.fit(Xtrain, ytrain, batch_size=64, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 6ms/step - loss: 0.0428 - accuracy: 0.9873\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0427795872092247, 0.9873060584068298]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 將測試的語句轉為索引後，預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.8375064e-01],\n",
       "       [9.6081186e-04]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = ['i like the movie very much', 'i hate it']\n",
    "test_sequences = tokenizer.texts_to_sequences(x)\n",
    "\n",
    "# Pad the testing sequences\n",
    "test_padded = pad_sequences(test_sequences, padding=pad_type, truncating=trunc_type, maxlen=maxlen)\n",
    "\n",
    "model.predict(test_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "bidirectional_lstm_imdb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
