{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "wordcloud_cn.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jumbokh/nknu-class/blob/main/NLP/notebooks/wordcloud_cn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcgSEAEoW3GS"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4murD-ZW8VR"
      },
      "source": [
        "!PIP install jieba"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3L6HxCuW3GU"
      },
      "source": [
        "\n",
        "# create wordcloud with chinese\n",
        "\n",
        "Wordcloud is a very good tool, but if you want to create\n",
        "Chinese wordcloud only wordcloud is not enough. The file\n",
        "shows how to use wordcloud with Chinese. First, you need a\n",
        "Chinese word segmentation library jieba, jieba is now the\n",
        "most elegant the most popular Chinese word segmentation tool in python.\n",
        "You can use 'PIP install jieba'. To install it. As you can see,\n",
        "at the same time using wordcloud with jieba very convenient\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYt-lcVdW3GX"
      },
      "source": [
        "import jieba\n",
        "jieba.enable_parallel(4)\n",
        "# Setting up parallel processes :4 ,but unable to run on Windows\n",
        "from os import path\n",
        "from imageio import imread\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "# jieba.load_userdict(\"txt\\userdict.txt\")\n",
        "# add userdict by load_userdict()\n",
        "from wordcloud import WordCloud, ImageColorGenerator\n",
        "\n",
        "# get data directory (using getcwd() is needed to support running example in generated IPython notebook)\n",
        "d = path.dirname(__file__) if \"__file__\" in locals() else os.getcwd()\n",
        "\n",
        "stopwords_path = d + '/wc_cn/stopwords_cn_en.txt'\n",
        "# Chinese fonts must be set\n",
        "font_path = d + '/fonts/SourceHanSerif/SourceHanSerifK-Light.otf'\n",
        "\n",
        "# the path to save worldcloud\n",
        "imgname1 = d + '/wc_cn/LuXun.jpg'\n",
        "imgname2 = d + '/wc_cn/LuXun_colored.jpg'\n",
        "# read the mask / color image taken from\n",
        "back_coloring = imread(path.join(d, d + '/wc_cn/LuXun_color.jpg'))\n",
        "\n",
        "# Read the whole text.\n",
        "text = open(path.join(d, d + '/wc_cn/CalltoArms.txt')).read()\n",
        "\n",
        "# if you want use wordCloud,you need it\n",
        "# add userdict by add_word()\n",
        "userdict_list = ['阿Ｑ', '孔乙己', '单四嫂子']\n",
        "\n",
        "\n",
        "# The function for processing text with Jieba\n",
        "def jieba_processing_txt(text):\n",
        "    for word in userdict_list:\n",
        "        jieba.add_word(word)\n",
        "\n",
        "    mywordlist = []\n",
        "    seg_list = jieba.cut(text, cut_all=False)\n",
        "    liststr = \"/ \".join(seg_list)\n",
        "\n",
        "    with open(stopwords_path, encoding='utf-8') as f_stop:\n",
        "        f_stop_text = f_stop.read()\n",
        "        f_stop_seg_list = f_stop_text.splitlines()\n",
        "\n",
        "    for myword in liststr.split('/'):\n",
        "        if not (myword.strip() in f_stop_seg_list) and len(myword.strip()) > 1:\n",
        "            mywordlist.append(myword)\n",
        "    return ' '.join(mywordlist)\n",
        "\n",
        "\n",
        "wc = WordCloud(font_path=font_path, background_color=\"white\", max_words=2000, mask=back_coloring,\n",
        "               max_font_size=100, random_state=42, width=1000, height=860, margin=2,)\n",
        "\n",
        "\n",
        "wc.generate(jieba_processing_txt(text))\n",
        "\n",
        "# create coloring from image\n",
        "image_colors_default = ImageColorGenerator(back_coloring)\n",
        "\n",
        "plt.figure()\n",
        "# recolor wordcloud and show\n",
        "plt.imshow(wc, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "# save wordcloud\n",
        "wc.to_file(path.join(d, imgname1))\n",
        "\n",
        "# create coloring from image\n",
        "image_colors_byImg = ImageColorGenerator(back_coloring)\n",
        "\n",
        "# show\n",
        "# we could also give color_func=image_colors directly in the constructor\n",
        "plt.imshow(wc.recolor(color_func=image_colors_byImg), interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.figure()\n",
        "plt.imshow(back_coloring, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "# save wordcloud\n",
        "wc.to_file(path.join(d, imgname2))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}