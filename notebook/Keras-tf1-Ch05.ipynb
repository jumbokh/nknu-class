{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "name": "Ch05.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jumbokh/nknu-class/blob/main/notebook/Keras-tf1-Ch05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dE2IJSu6X4SC"
      },
      "source": [
        "# 5-1 卷積神經網路 CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXGUah_hX4SI"
      },
      "source": [
        "### 程式 5.1 初始化一個小型卷積神經網路 (convnet)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "a6MC59ulX4SL"
      },
      "source": [
        "from keras import layers  # 從 keras 套件匯入 layers, models 套件\n",
        "from keras import models\n",
        "\n",
        "model = models.Sequential() \n",
        "\t\t     #過濾器數量 ↓      ↓過濾器長寬\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1))) # 加入 Covn2d 層\n",
        "model.add(layers.MaxPooling2D((2, 2))) # 進行 MaxPooling\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eeEMgbgX4SO"
      },
      "source": [
        "### 程式 5.2 在卷積神經網路上加入分類器"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "f0U3IFBhX4SP"
      },
      "source": [
        "model.add(layers.Flatten())  # 將 3D 張量展開攤平為 1D, 其 shape = (576, )\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yv6Sc_aiX4SP"
      },
      "source": [
        "### 程式 5.3 用 MNIST 影像訓練卷積神經網路"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Z4oa8iJwX4SQ"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "loss='categorical_crossentropy',\n",
        "metrics=['accuracy'])\n",
        "model.fit(train_images, train_labels, epochs=5, batch_size=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCGnr8jDX4SR"
      },
      "source": [
        "### 用測試資料來評估 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "-K_Lo5tqX4SS"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "test_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7niGqmxkX4SU"
      },
      "source": [
        "# 5-2 以少量資料集從頭訓練一個卷積神經網路"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOwxjNolX4SU"
      },
      "source": [
        "### 程式 5.4 複製圖片到訓練、驗證和測試集目錄"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "tiIY8x-6X4SU"
      },
      "source": [
        "import os, shutil\n",
        "\n",
        "# 解壓縮資料夾所在的目錄路徑\n",
        "original_dataset_dir = r'C:\\Users\\Admin\\Desktop\\Google\\Python Keras\\ch05\\dogs-vs-cats\\train\\train' \n",
        "# 用來儲存少量資料集的目錄位置\n",
        "base_dir = r'C:\\Users\\Admin\\Desktop\\Google\\Python Keras\\ch05\\cats_and_dogs_small' \n",
        "if not os.path.isdir(base_dir): os.mkdir(base_dir)  # 如果目錄不存在, 才建立目錄\n",
        "\n",
        "# 分拆成訓練、驗證與測試目錄位置\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "if not os.path.isdir(train_dir): os.mkdir(train_dir)\n",
        "\n",
        "validation_dir = os.path.join(base_dir, 'validation')  \n",
        "if not os.path.isdir(validation_dir): os.mkdir(validation_dir)\n",
        "    \n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "if not os.path.isdir(test_dir): os.mkdir(test_dir)\n",
        "\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "if not os.path.isdir(train_cats_dir): \n",
        "    os.mkdir(train_cats_dir) # 用來訓練貓圖片的目錄位置\n",
        "\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "if not os.path.isdir(train_dogs_dir): \n",
        "    os.mkdir(train_dogs_dir) # 用來訓練狗圖片的目錄位置\n",
        "\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "if not os.path.isdir(validation_cats_dir): \n",
        "    os.mkdir(validation_cats_dir) # 用來驗證貓圖片的目錄位置\n",
        "\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
        "if not os.path.isdir(validation_dogs_dir): \n",
        "    os.mkdir(validation_dogs_dir) # 用來驗證狗圖片的目錄位置\n",
        "\n",
        "test_cats_dir = os.path.join(test_dir, 'cats')\n",
        "if not os.path.isdir(test_cats_dir): \n",
        "    os.mkdir(test_cats_dir) # 用來測試貓圖片的目錄位置\n",
        "\n",
        "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
        "if not os.path.isdir(test_dogs_dir): \n",
        "    os.mkdir(test_dogs_dir) # 用來測試狗圖片的目錄位置\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 複製前面 1000 張貓圖片到 train_cats_dir 訓練目錄\n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(1000)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(train_cats_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "# 複製下 500 張貓圖片到 validation_cats_dir 驗證目錄\n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(validation_cats_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "# 複製下 500 張貓圖片到 test_cats_dir 測試目錄\n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(test_cats_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "# 複製前面 1000 張狗圖片到 train_dogs_dir 訓練目錄\n",
        "fnames = ['dog.{}.jpg'.format(i) for i in range(1000)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(train_dogs_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "# 複製下 500 張狗圖片到 validation_dogs_dir 驗證目錄\n",
        "fnames = ['dog.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(validation_dogs_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "# 複製下 500 張狗圖片到 test_dogs_dir 測試目錄\n",
        "fnames = ['dog.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(test_dogs_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "print('複製完成')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvKUCCSMX4SV"
      },
      "source": [
        "### 我們計算每個訓練/驗證/測試分組中的圖片數量，做為資料完整性的檢查："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "f4F9paUnX4SW"
      },
      "source": [
        "print('訓練用的貓照片張數:', len(os.listdir(train_cats_dir)))\n",
        "print('訓練用的狗照片張數:', len(os.listdir(train_dogs_dir)))\n",
        "print('驗證用的貓照片張數:', len(os.listdir(validation_cats_dir)))\n",
        "print('驗證用的狗照片張數:', len(os.listdir(validation_dogs_dir)))\n",
        "print('測試用的貓照片張數:', len(os.listdir(test_cats_dir)))\n",
        "print('測試用的狗照片張數:', len(os.listdir(test_dogs_dir)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfbOosoUX4SX"
      },
      "source": [
        "### 程式 5.5 為狗 vs. 貓分類實作的一個小型的卷積神經網路"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "GZt2zf2WX4SX"
      },
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
        "                        input_shape=(150, 150, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.summary()  # 查看模型摘要"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1O6BXaJX4SX"
      },
      "source": [
        "### 程式 5.6 配置 model 以進行訓練"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "gBpMjIS8X4SY"
      },
      "source": [
        "from keras import optimizers\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzUyUgTTX4SY"
      },
      "source": [
        "### 程式 5.7 使用 ImageDataGenerator 產生器從目錄中讀取影像"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "mP5-ZMuIX4SY"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255) #設定訓練、測試資料的 Python 產生器，並將圖片像素值依 1/255 比例重新壓縮到 [0, 1]\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,              # 目標目錄\n",
        "    target_size=(150, 150),  # 調整所有影像大小成 150x150\n",
        "    batch_size=20,\n",
        "    class_mode='binary')    # 因為使用二元交叉熵 binary_crossentropy 作為損失值，所以需要二位元標籤\n",
        "\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=20,\n",
        "    class_mode='binary')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfPnqFTuX4SZ"
      },
      "source": [
        "### 看看產生器的輸出結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "HWTnJP6XX4SZ"
      },
      "source": [
        "for data_batch, labels_batch in train_generator:\n",
        "    print('data batch shape:', data_batch.shape)\n",
        "    print('labels batch shape:', labels_batch.shape)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttIPOJ_1X4SZ"
      },
      "source": [
        "### 程式 5.8 調整 model 以使用批次量產生器"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "scrolled": true,
        "id": "YoUmVQPQX4SZ"
      },
      "source": [
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=30,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0SAHNA7X4Sa"
      },
      "source": [
        "### 程式 5.9 儲存model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "StE1ljmpX4Sa"
      },
      "source": [
        "model.save('cats_and_dogs_small_1.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFct_QUKX4Sa"
      },
      "source": [
        "### 程式 5.10 顯示訓練和驗證週期的損失值和準確度曲線"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "R6-mEIF9X4Sa"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hi4fTzpXX4Sb"
      },
      "source": [
        "### 程式 5.11 透過 ImageDataGenerator 設定資料擴增"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "_pBUwmnNX4Sb"
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIUvucruX4Sb"
      },
      "source": [
        "### 程式 5.12 顯示一些隨機擴充的訓練影像"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "jaWgMcYVX4Sb"
      },
      "source": [
        "from keras.preprocessing import image\n",
        "\n",
        "fnames = [os.path.join(train_cats_dir, fname) for\n",
        "    fname in os.listdir(train_cats_dir)]\n",
        "\n",
        "img_path = fnames[3]\n",
        "\n",
        "img = image.load_img(img_path, target_size=(150, 150))\n",
        "\n",
        "x = image.img_to_array(img)\n",
        "\n",
        "x = x.reshape((1, ) + x.shape)\n",
        "\n",
        "i = 0\n",
        "for batch in datagen.flow(x, batch_size=1):\n",
        "    plt.figure(i)\n",
        "    imgplot = plt.imshow(image.array_to_img(batch[0]))\n",
        "    i += 1\n",
        "    if i % 4 == 0:\n",
        "        break\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51jkpnLDX4Sb"
      },
      "source": [
        "### 程式 5.13 定義具有 Dropout 層的新卷積神經網路"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "bXWUfdbfX4Sb"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
        "                        input_shape=(150, 150, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dropout(0.5))  #  在這裡加入 Dropout 層 (丟棄 50 %)\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBala1kkX4Sc"
      },
      "source": [
        "### 程式 5.14 使用資料擴增產生器來訓練卷積神經網路"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Ur3YTUtYX4Sc"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True, )\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255) # 請注意！驗證資料不應該擴充!!!\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "\ttrain_dir,    # 目標目錄\n",
        "\ttarget_size=(150, 150), # 所有圖像大小調整成 150×150 \n",
        "\tbatch_size=32,\n",
        "\tclass_mode='binary') # 因為使用二元交叉熵 binary_crossentropy 作為損失，所以需要二元標籤\n",
        "\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "\tvalidation_dir,\n",
        "\ttarget_size=(150, 150),\n",
        "\tbatch_size=32,\n",
        "\tclass_mode='binary')\n",
        "\n",
        "# 訓練\n",
        "history = model.fit_generator(   \n",
        "\ttrain_generator,\n",
        "\tsteps_per_epoch=100,\n",
        "\tepochs=100,\n",
        "\tvalidation_data=validation_generator,\n",
        "\tvalidation_steps=50)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nenMdt4hX4Sc"
      },
      "source": [
        "### 程式 5.15 儲存 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "CICrMQo7X4Sd"
      },
      "source": [
        "model.save('cats_and_dogs_small_2.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NT9KvnZuX4Sd"
      },
      "source": [
        "### 再次顯示訓練和驗證週期的損失值和準確度曲線"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "K_8UUroaX4Sd"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ds1FlFTPX4Sd"
      },
      "source": [
        "# 5-3 使用預先訓練的卷積神經網路"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6dxzuT2X4Sd"
      },
      "source": [
        "## 5-3-1 特徵萃取"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNdzI4usX4Sd"
      },
      "source": [
        "### 沒有資料擴增的快速特徵萃取"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CFXWX35X4Se"
      },
      "source": [
        "### 程式 5.16 實作 VGG16 convolutional base 卷積基底"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "DWXT-yWMX4Se"
      },
      "source": [
        "from keras.applications import VGG16\n",
        "\n",
        "conv_base = VGG16(weights='imagenet',\n",
        "                  include_top=False,\n",
        "                  input_shape=(150, 150, 3))\n",
        "conv_base.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkntH90SX4Se"
      },
      "source": [
        "### 程式 5.17 使用預先訓練的 convolutional base 萃取特徵"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "ZN9_KCAmX4Se"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "base_dir = r'C:\\Users\\Admin\\Desktop\\Google\\Python Keras\\ch05\\cats_and_dogs_small' \n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "batch_size = 20\n",
        "\n",
        "def extract_features(directory, sample_count):\n",
        "    features = np.zeros(shape=(sample_count, 4, 4, 512))\n",
        "    labels = np.zeros(shape=(sample_count))\n",
        "    generator = datagen.flow_from_directory(directory,\n",
        "                                            target_size=(150, 150),\n",
        "                                            batch_size=batch_size,\n",
        "                                            class_mode='binary')\n",
        "    i = 0\n",
        "    for inputs_batch, labels_batch in generator:\n",
        "        features_batch = conv_base.predict(inputs_batch)\n",
        "        features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
        "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
        "        i += 1\n",
        "        print(i, end=' ') # 由於萃取需要較長的時間，我們印出 i 來檢視進度\n",
        "        if i * batch_size >= sample_count:\n",
        "            break\n",
        "    return features, labels\n",
        "\n",
        "train_features, train_labels = extract_features(train_dir, 2000)\n",
        "validation_features, validation_labels = extract_features(validation_dir, 1000)\n",
        "test_features, test_labels = extract_features(test_dir, 1000)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PknEubVcX4Se"
      },
      "source": [
        "### 程式 5.18 將資料展平"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "8AvWa4dEX4Se"
      },
      "source": [
        "train_features = np.reshape(train_features, (2000, 4 * 4 * 512))\n",
        "validation_features = np.reshape(validation_features, (1000, 4 * 4 * 512))\n",
        "test_features = np.reshape(test_features, (1000, 4 * 4 * 512))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cMQmVhaX4Se"
      },
      "source": [
        "### 程式 5.19 定義和訓練密集連接的分類器"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "KLRcvXYrX4Sf"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(256, activation='relu', input_dim=4 * 4 * 512))\n",
        "model.add(layers.Dropout(0.5))  # 丟棄法\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=2e-5),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])\n",
        "\n",
        "history = model.fit(train_features, \n",
        "                    train_labels,epochs=30,\n",
        "                    batch_size=20,\n",
        "                    validation_data=(validation_features, validation_labels))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeYyVKRLX4Sf"
      },
      "source": [
        "### 程式 5.20 繪製結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "jxCC5amgX4Sf"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jX7zcCbYX4Sf"
      },
      "source": [
        "## 資料擴增的特徵萃取"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJ1ZfMA4X4Sf"
      },
      "source": [
        "### 程式 5.21 在 convolutional base 卷積基底上增加密集層分類器"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "LMPeCDNHX4Sf"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras.applications import VGG16\n",
        "\n",
        "conv_base = VGG16(weights='imagenet',   # 卷積基底\n",
        "                  include_top=False,\n",
        "                  input_shape=(150, 150, 3))\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(conv_base)        # 將卷積基底視為層加入 Sequential 模型中\n",
        "model.add(layers.Flatten()) # 攤平\n",
        "model.add(layers.Dense(256, activation='relu')) \n",
        "model.add(layers.Dense(1, activation='sigmoid')) # 增加密集層分類器\n",
        "model.summary() # 查看模型摘要"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlM3IdM1X4Sf"
      },
      "source": [
        "### 程式 5.22 凍結卷積基底神經網路"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "soY9Ia1cX4Sg"
      },
      "source": [
        "print('This is the number of trainable weights '\n",
        "'before freezing the conv base:', len(model.trainable_weights))\n",
        "\n",
        "conv_base.trainable = False  \n",
        "\n",
        "print('This is the number of trainable weights '\n",
        "'after freezing the conv base:', len(model.trainable_weights))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzWh5fnpX4Sg"
      },
      "source": [
        "### 程式 5.23 以凍結的 convolutional base 卷積基底進行從頭到尾完整的 model 訓練"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "7XRlsfP8X4Sg"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "\n",
        "train_datagen = ImageDataGenerator( # 擴充訓練資料\n",
        "\trescale=1./255,\n",
        "\trotation_range=40,\n",
        "\twidth_shift_range=0.2,\n",
        "\theight_shift_range=0.2,\n",
        "\tshear_range=0.2,\n",
        "\tzoom_range=0.2,\n",
        "\thorizontal_flip=True,\n",
        "\tfill_mode='nearest')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255) # 請注意驗證資料不應該擴充\n",
        "\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "\ttrain_dir, # 目標目錄路徑\n",
        "\ttarget_size=(150, 150), # 調整所有圖像大小成 150×150 \n",
        "\tbatch_size=20,\n",
        "\tclass_mode='binary') # 因為使用二元交叉熵 binary_crossentropy 作為損失分數，所\t\t\t\t\t\t以需要二元標籤\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "\tvalidation_dir,\n",
        "\ttarget_size=(150, 150),\n",
        "\tbatch_size=20,\n",
        "\tclass_mode='binary')\n",
        "\n",
        "model.compile( loss='binary_crossentropy',\n",
        "\t\t\t optimizer=optimizers.RMSprop(lr=2e-5),\n",
        "\t\t\t metrics=['acc'])\n",
        "\n",
        "history = model.fit_generator(\n",
        "\ttrain_generator,\n",
        "\tsteps_per_epoch=100,\n",
        "\tepochs=30,\n",
        "\tvalidation_data=validation_generator,\n",
        "\tvalidation_steps=50)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "mDIA7xLmX4Sg"
      },
      "source": [
        "\"\"\" 若你的 Keras 版本執行程式 5.23 後的結果與書上有所差異，請將程式 5.23 做以下的修改\n",
        "\n",
        "這邊提供 2 種修改方式：\n",
        "\n",
        "方式 1. 將 conv_base.trainable = False  註解掉。\n",
        "\n",
        "方式 2. 餵給 VGG16 的圖片像素值不要壓到 0-1 之間，將 rescale=1./255 都註解掉，在程式 5.23 中做以下的修改：\n",
        "\n",
        "from keras.applications.imagenet_utils import preprocess_input  # 新增這行\n",
        "\n",
        "train_gen = ImageDataGenerator(\n",
        "#     rescale=1.0/255,                       # 註解這行\n",
        "    preprocessing_function=preprocess_input, # 新增這行\n",
        "    height_shift_range=0.2,\n",
        "    width_shift_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    rotation_range=40,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "#test_datagen = ImageDataGenerator(1./255)                                 # 註解這行\n",
        "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input) # 新增這行\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpCBUt25X4Sg"
      },
      "source": [
        "#### 繪製結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "M1z-hOS4X4Sh"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-51UiYsX4Sh"
      },
      "source": [
        "### 5-3-2 微調"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULVj50gsX4Sh"
      },
      "source": [
        "### 程式 5.24 將所有層凍結到指定層為止"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "yultGlpfX4Sh"
      },
      "source": [
        "from keras.applications import VGG16\n",
        "\n",
        "conv_base = VGG16(weights='imagenet',\n",
        "                  include_top=False,\n",
        "                  input_shape=(150, 150, 3))\n",
        "conv_base.summary()\n",
        "\n",
        "conv_base.trainable = True\n",
        "set_trainable = False\n",
        "\n",
        "for layer in conv_base.layers:\n",
        "    if layer.name == 'block5_conv1':\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PETyvrkVX4Sh"
      },
      "source": [
        "### 程式 5.25 微調神經網路"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "qphuKmzxX4Sh"
      },
      "source": [
        "# 編譯模型\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=optimizers.RMSprop(lr=1e-5),\n",
        "    metrics=['acc'])\n",
        "\n",
        "# 訓練模型\n",
        "history = model.fit_generator(   \n",
        "    train_generator,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=100,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lzCDKZyX4Sh"
      },
      "source": [
        "#### 繪製結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "qYzRhARqX4Si"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f39BPwwX4Si"
      },
      "source": [
        "### 程式 5.26 繪製平滑曲線"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "zQ2S_LqlX4Si"
      },
      "source": [
        "def smooth_curve(points, factor=0.8):\n",
        "\tsmoothed_points = []\n",
        "\tfor point in points:\n",
        "\t\tif smoothed_points:\n",
        "\t\t\tprevious = smoothed_points[-1]\n",
        "\t\t\tsmoothed_points.append(previous * factor + point * (1 - factor))\n",
        "\t\telse:\n",
        "\t\t\tsmoothed_points.append(point)\n",
        "\treturn smoothed_points\n",
        "\n",
        "plt.plot( epochs,\n",
        "\t   smooth_curve(acc), 'bo', label='Smoothed training acc')\n",
        "plt.plot( epochs,\n",
        "\t   smooth_curve(val_acc), 'b', label='Smoothed validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot( epochs,\n",
        "\t   smooth_curve(loss), 'bo', label='Smoothed training loss')\n",
        "plt.plot( epochs,\n",
        "\t   smooth_curve(val_loss), 'b', label='Smoothed validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyubfBYHX4Si"
      },
      "source": [
        "### 程式 5.27 使用測試資料來評估微調後的 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "g4N1fiRXX4Si"
      },
      "source": [
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=20,\n",
        "    class_mode='binary')\n",
        "\n",
        "test_loss, test_acc = model.evaluate_generator(test_generator, steps=50)\n",
        "print('test acc:', test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKQOkEKoX4Si"
      },
      "source": [
        "# 5-4 視覺化呈現卷積神經網路學習的內容"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "op2lJqENX4Si"
      },
      "source": [
        "### 5-4-1 中間層輸出的視覺化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IRe1C4HX4Sj"
      },
      "source": [
        "### 程式 5.28 載入 5-2 節程式 5.15 中已建立並儲存的 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "6VLvJxFEX4Sj"
      },
      "source": [
        "from keras.models import load_model\n",
        "model = load_model(r'cats_and_dogs_small_2.h5')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9WdtWjAX4Sj"
      },
      "source": [
        "### 程式 5.29 預處理 (preprocessing) 單張圖片"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "ePicCfQXX4Sj"
      },
      "source": [
        "img_path = r'C:\\Users\\Admin\\Desktop\\Google\\Python Keras\\ch05\\cats_and_dogs_small\\test\\cats\\cat.1700.jpg'\n",
        "\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# 將這張圖片預處理成 4D 張量並將像素值限制在 0-1 之間\n",
        "img = image.load_img(img_path, target_size=(150, 150))\n",
        "img_tensor = image.img_to_array(img)\n",
        "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
        "img_tensor /= 255.\n",
        "\n",
        "print(img_tensor.shape) # shape = (1, 150, 150, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYydoStBX4Sj"
      },
      "source": [
        "### 程式 5.30 顯示測試影像"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "scrolled": true,
        "id": "tsKWAC1TX4Sj"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(img_tensor[0])\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLrWYqHsX4Sj"
      },
      "source": [
        "### 程式 5.31 用一個輸入張量和一個輸出張量 list (8個層) 來建構一個model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "twNmU05VX4Sk"
      },
      "source": [
        "from keras import models \n",
        "\n",
        "layer_outputs = [layer.output for layer in model.layers[:8]]\n",
        "for op in layer_outputs: \n",
        "    print(op)\n",
        "\n",
        "activation_model = models.Model(inputs=model.input, outputs=layer_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7rTfmnSX4Sk"
      },
      "source": [
        "### 程式 5.32 在 predict mode 下執行 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "TkD82R66X4Sk"
      },
      "source": [
        "activations = activation_model.predict(img_tensor)\n",
        "print(len(activations))\n",
        "\n",
        "first_layer_activation = activations[0]\n",
        "print(first_layer_activation.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVaJIlMOX4Sk"
      },
      "source": [
        "### 程式 5.33 視覺化 (繪製) 第 4 個 channel 的特徵圖"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "ZJdGPlyGX4Sk"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.matshow(first_layer_activation[0, :, :, 4], cmap='viridis')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgCh3YzJX4Sk"
      },
      "source": [
        "### 程式 5.34 視覺化 (繪製) 第 7 個 channel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "m9QZXuT_X4Sk"
      },
      "source": [
        "plt.matshow(first_layer_activation[0, :, :, 7], cmap='viridis')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lw4e1LfqX4Sk"
      },
      "source": [
        "### 程式 5.35 視覺化 (繪製) 每個啟動函數輸出中每個 channel 的特徵圖"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "IfXbeMT9X4Sl"
      },
      "source": [
        "layer_names = []\n",
        "\n",
        "# 取得各層的名字，這樣才可以成為圖表的一部分\n",
        "for layer in model.layers[:8]:\n",
        "    layer_names.append(layer.name)\n",
        "\n",
        "images_per_row = 16\n",
        "\n",
        "for layer_name, layer_activation in zip(layer_names, activations):\n",
        "    n_features = layer_activation.shape[-1]\n",
        "    size = layer_activation.shape[1]\n",
        "\n",
        "    n_cols = n_features // images_per_row\n",
        "    display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
        "\n",
        "    for col in range(n_cols):\n",
        "        for row in range(images_per_row):\n",
        "            channel_image = layer_activation[0, :, :, col * images_per_row + row]\n",
        "            channel_image -= channel_image.mean()\n",
        "            channel_image /= channel_image.std()\n",
        "            channel_image *= 64\n",
        "            channel_image += 128\n",
        "            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
        "            display_grid[col * size : (col + 1) * size,\n",
        "                         row * size : (row + 1) * size] = channel_image\n",
        "\n",
        "    scale = 1. / size\n",
        "    plt.figure(figsize=(scale * display_grid.shape[1],\n",
        "    scale * display_grid.shape[0]))\n",
        "    plt.title(layer_name)\n",
        "    plt.grid(False)\n",
        "    plt.imshow(display_grid, aspect='auto', cmap='viridis')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "LJRHI8_lX4Sl"
      },
      "source": [
        "### 5-4-2 視覺化 convnet 的 filter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "kgDOw6iQX4Sl"
      },
      "source": [
        "### 程式 5.36 建立 (定義) 過濾器視覺化的損失函數張量"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "z2Mr13LYX4Sl"
      },
      "source": [
        "from keras.applications import VGG16\n",
        "from keras import backend as K\n",
        "\n",
        "model = VGG16(weights='imagenet',\n",
        "              include_top=False)\n",
        "\n",
        "layer_name = 'block3_conv1'\n",
        "filter_index = 0\n",
        "\n",
        "layer_output = model.get_layer(layer_name).output \n",
        "loss = K.mean(layer_output[:, :, :, filter_index]) # 定義損失函數張量, 其為層輸出張量數值取平均\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "GGDlxAStX4Sl"
      },
      "source": [
        "### 程式 5.37 取得損失值 (loss) 相對於輸入 (model.input) 的梯度"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "5PYPwUwJX4Sl"
      },
      "source": [
        "# gradients() 會傳回一個由張量組成的list, 在本例中, list 的大小為 1, 因此, 只取出其第 0 個元素, 即 grads 是 1 個梯度張量\n",
        "grads = K.gradients(loss, model.input)[0] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "DToYca-YX4Sl"
      },
      "source": [
        "### 程式 5.38 梯度正規化技巧"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "gdm79nv-X4Sm"
      },
      "source": [
        "# 在做除法之前先加上 1e-5 以避免意外地除以 0\n",
        "grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "Aj1YOlMDX4Sm"
      },
      "source": [
        "### 程式 5.39 建立給定輸入張量, 取得輸出張量的 Keras function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "DZ99zXmjX4Sm"
      },
      "source": [
        "iterate = K.function([model.input], [loss, grads]) # 定義一個 Keras 後端函式\n",
        "\n",
        "import numpy as np\n",
        "loss_value, grads_value = iterate([np.zeros((1, 150, 150, 3))])\n",
        "#輸出損失張量與梯度張量\t\t\t\t↑將此做為輸入張量"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "O97UBGkuX4Sm"
      },
      "source": [
        "### 程式 5.40 透過隨機梯度上升實作損失最大化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "-ZixstL-X4Sm"
      },
      "source": [
        "# 從帶有雜訊的灰階圖像開始\n",
        "input_img_data = np.random.random((1, 150, 150, 3)) * 20 + 128. # 1...\n",
        "\n",
        "step = 1. # 每個梯度更新的大小\n",
        "for i in range(40): # 執行梯度上升 40 步\n",
        "\tloss_value, grads_value = iterate([input_img_data]) # 計算損失值和梯度值\n",
        "\tinput_img_data += grads_value * step # 2. 以朝向最大化損失調整輸入圖像 (以前SGD 是用 -= 算符, 現在反過來是用 += 算符)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "gkUI6DlOX4Sm"
      },
      "source": [
        "### 程式 5.41 建立將圖像張量轉換為可用的影像格式的自訂函式"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Ih9NK4rJX4Sm"
      },
      "source": [
        "def deprocess_image(x):\n",
        "    x -= x.mean()\n",
        "    x /= (x.std() + 1e-5)\t\t\t\t# 1. 張量正規化：以 0 為中心, 確保 std 為 0.1 \n",
        "    x *= 0.1\n",
        "    \n",
        "    x += 0.5\n",
        "    x = np.clip(x, 0, 1) # 修正成 [0, 1], 即 0-1 之間 \n",
        "    \n",
        "    x *= 255\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\t\t# 2.轉換成 RGB 陣列\n",
        "    return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "XkXdj3GAX4Sn"
      },
      "source": [
        "### 程式 5.42 建立視覺化過濾器的函式"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "QVXNmFiRX4Sn"
      },
      "source": [
        "def generate_pattern(layer_name, filter_index, size=150):\n",
        "\tlayer_output = model.get_layer(layer_name).output # 取得指定層的輸出張量\n",
        "\tloss = K.mean(layer_output[:, :, :, filter_index]) # 1. 取得指定過濾器的輸出張量, 並以最大化此張量的均值做為損失\n",
        "\n",
        "\n",
        "\tgrads = K.gradients(loss, model.input)[0] # 根據此損失計算輸入影像的梯度\n",
        "\n",
        "\tgrads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5) # 標準化技巧：梯度標準化\n",
        "\n",
        "\titerate = K.function([model.input], [loss, grads]) # 2.建立 Keras function 來針對給定的輸入影像回傳損失和梯度\n",
        "\n",
        "\tinput_img_data = np.random.random((1, size, size, 3)) * 20 + 128. # 3. 從帶有雜訊的灰階影像開始\n",
        "\t\n",
        "\n",
        "\tstep = 1.\n",
        "\tfor i in range(40): # 執行梯度上升 40 步\n",
        "\t\tloss_value, grads_value = iterate([input_img_data]) # 4. 針對給定的輸入影像回傳損失和梯度\n",
        "\t\tinput_img_data += grads_value * step\n",
        "\n",
        "\timg = input_img_data[0]\n",
        "\treturn deprocess_image(img)\t  # 進行圖像後處理後回傳\n",
        "\n",
        "\n",
        "plt.imshow(generate_pattern('block3_conv1', 0)) # 我們來看看 block3_conv1 層中的過濾器 0 的特徵圖"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "Mj7z--UJX4Sn"
      },
      "source": [
        "### 程式 5.43 產生一層中所有的過濾器響應 pattern"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "wDTnuDboX4Sn"
      },
      "source": [
        "for layer_name in ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1']:\n",
        "    size = 64\n",
        "    margin = 5\n",
        "\n",
        "    # 1. 用於儲存結果的空(黑色)影像\n",
        "    results = np.zeros((8 * size + 7 * margin, 8 * size + 7 * margin, 3))\n",
        "\n",
        "    for i in range(8):  # ← 迭代產生網格的行\n",
        "        for j in range(8):  # ←迭代產生網格的列\n",
        "            # 在 layer_name 中產生過濾器 i +(j * 8) 的 pattern\n",
        "            filter_img = generate_pattern(layer_name, i + (j * 8), size=size)\n",
        "\n",
        "            # 將結果放在結果網格的方形(i, j)中\n",
        "            horizontal_start = i * size + i * margin\n",
        "            horizontal_end = horizontal_start + size\n",
        "            vertical_start = j * size + j * margin\n",
        "            vertical_end = vertical_start + size\n",
        "            results[horizontal_start: horizontal_end, vertical_start: vertical_end, :] = filter_img\n",
        "\n",
        "    # 顯示網格結果\n",
        "    plt.figure(figsize=(20, 20))\n",
        "    plt.imshow(results)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWK9N1zDX4Sn"
      },
      "source": [
        "### 5-4-3 視覺化類別激活熱圖 heatmap of class activation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6LhyYRbX4Sn"
      },
      "source": [
        "### 程式 5.44 載入預先訓練權重的 VGG16 神經網路"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Hygsl-naX4So"
      },
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        " \n",
        "model = VGG16(weights='imagenet')  # 請注意, 在頂部包含了密集連接的分類器 (預設 include_top=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzW8vlLGX4So"
      },
      "source": [
        "### 程式5.45 預先處理 VGG16 的輸入影像"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "0S3shEysX4So"
      },
      "source": [
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "import numpy as np\n",
        "\n",
        "img_path = r'C:\\Users\\Admin\\Desktop\\Google\\Python Keras\\ch05\\african_elephants.jpg'\n",
        "\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "print(type(img))  # 目前圖片為 <class 'PIL.Image.Image'> 物件\n",
        "print(img.size)  # 可以用 size 屬性查看尺寸 -> (224, 224)\n",
        "\n",
        "x = image.img_to_array(img) \t# 將 PIL 物件轉為 float32 的 Numpy 陣列\n",
        "print(x.shape) \t\t\t\t# shape=(224, 224, 3)\n",
        "\n",
        "\n",
        "# 將 x 陣列 (可視為張量) 增加一個批次軸, shape=(1, 224, 224, 3)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "print(x.shape)\n",
        "\n",
        "x = preprocess_input(x) # 預處理批次量 (這會對每一 channel 做顏色值正規化)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vs9aMEmDX4So"
      },
      "source": [
        "### 程式 5.46 使用 VGG 神經網路預測圖片類別"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "FwQ2KcNfX4So"
      },
      "source": [
        "preds = model.predict(x)\n",
        "print('預測結果:', decode_predictions(preds, top=3)[0])\n",
        "\n",
        "np.argmax(preds[0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9AMHPruX4So"
      },
      "source": [
        "### 程式 5.47 設定 Gard-CAM 演算法"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "i77XX89WX4So"
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "african_elephant_output = model.output[:, 386] # ← 預測向量中的 \"非洲象\" 項目\n",
        "\n",
        "last_conv_layer = model.get_layer('block5_conv3') # block5_conv3 層的輸出特徵圖, 其為 VGG16 中的最後一個卷積層\n",
        "\n",
        "grads = K.gradients(african_elephant_output, last_conv_layer.output)[0] #  block5_conv3 的輸出特徵圖中關於 \"非洲象\" 類別的梯度\n",
        "\n",
        "pooled_grads = K.mean(grads, axis=(0, 1, 2)) #  轉換成向量 shape = (512, ), 其中每個項目是特定特徵圖 channel 的梯度平均強度(值)\n",
        "\n",
        "#  給定輸入影像的條件下, 讓我們可以存取剛剛定義的數值：pooled_grads 和 block5_conv3 的輸出特徵圖\n",
        "iterate = K.function([model.input], \n",
        "    [pooled_grads, last_conv_layer.output[0]])\n",
        "\n",
        "#  對於給定的兩隻大象樣本影像, 產生這兩個量值, 以 Numpy 陣列呈現\n",
        "pooled_grads_value, conv_layer_output_value = iterate([x])\n",
        "\n",
        "# 將特徵圖陣列中的每個 channel 與 \"大象\" 類別相關的 \"此 channel 的重要程度\" 相乘\n",
        "for i in range(512):\n",
        "    conv_layer_output_value[:, :, i] *= pooled_grads_value[i]\n",
        "\n",
        "# 特徵圖的跨 channel 平均值是類別激活函數輸出的熱圖\n",
        "heatmap = np.mean(conv_layer_output_value, axis=-1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFi462XgX4Sp"
      },
      "source": [
        "### 程式 5.48 熱圖後期處理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Vp3EHrTyX4Sp"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "heatmap = np.maximum(heatmap, 0)\n",
        "heatmap /= np.max(heatmap)\n",
        "plt.matshow(heatmap)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhNDuvolX4Sp"
      },
      "source": [
        "### 程式 5.49 將熱圖與原始影像疊加在一起"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "_LIl9p3_X4Sp"
      },
      "source": [
        "import cv2\n",
        "\n",
        "img = cv2.imread(img_path)\n",
        "\n",
        "heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "\n",
        "heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "\n",
        "superimposed_img = heatmap * 0.4 + img # 這裡 0.4 是熱圖強度因子\n",
        "\n",
        "print('是否儲存成功:', cv2.imwrite('elephant_cam.jpg', superimposed_img))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "6gVHg7POX4Sp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "iopWxtH6X4Sp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "0z6ge1HcX4Sp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "XwLp58pIX4Sq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "ZLmYra9mX4Sq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "1lA3VFQFX4Sq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "FNaB_ivwX4Sq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "TZKhoLZRX4Sq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}