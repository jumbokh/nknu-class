{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Topic 2-ML_params_tuning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMg51/XDxvw/ZMzfEutWLuR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jumbokh/nknu-class/blob/main/notebook/Topic_2_ML_params_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0R1vLvnyYbE",
        "outputId": "0c23e4d8-a526-4339-8dfb-40ee34a25cd8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!ln -fs /content/gdrive/My\\ Drive /app"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dzqAAl7zoUe",
        "outputId": "b4d3493f-c29a-4ade-e514-52577b67d01d"
      },
      "source": [
        "!tar -xzvf /app/cuDNN/cudnn-10.0-linux-x64-v7.5.0.56.tgz -C /usr/local/\n",
        "!chmod a+r /usr/local/cuda/include/cudnn.h\n",
        "\n",
        "# 檢查是否安裝成功\n",
        "!cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda/include/cudnn.h\n",
            "cuda/NVIDIA_SLA_cuDNN_Support.txt\n",
            "cuda/lib64/libcudnn.so\n",
            "cuda/lib64/libcudnn.so.7\n",
            "cuda/lib64/libcudnn.so.7.5.0\n",
            "cuda/lib64/libcudnn_static.a\n",
            "#define CUDNN_MAJOR 7\n",
            "#define CUDNN_MINOR 5\n",
            "#define CUDNN_PATCHLEVEL 0\n",
            "--\n",
            "#define CUDNN_VERSION (CUDNN_MAJOR * 1000 + CUDNN_MINOR * 100 + CUDNN_PATCHLEVEL)\n",
            "\n",
            "#include \"driver_types.h\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKIOLXkvzT-e"
      },
      "source": [
        "### [Data source](https://github.com/coding-maniacs/machine_learning_parameter_tuning/tree/master/data) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPVJC5lzzNFM"
      },
      "source": [
        "import json as j\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScXOvVYO0GgX"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "Jdx6pkVu0N4H",
        "outputId": "db518e83-65e6-4d12-f914-ca5271c47dfc"
      },
      "source": [
        "json_data = None\n",
        "with open('/app/data/yelp_academic_dataset_review.json') as data_file:\n",
        "    lines = data_file.readlines()\n",
        "    joined_lines = \"[\" + \",\".join(lines) + \"]\"\n",
        "\n",
        "    json_data = j.loads(joined_lines)\n",
        "\n",
        "data = pd.DataFrame(json_data)\n",
        "data.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>votes</th>\n",
              "      <th>user_id</th>\n",
              "      <th>review_id</th>\n",
              "      <th>stars</th>\n",
              "      <th>date</th>\n",
              "      <th>text</th>\n",
              "      <th>type</th>\n",
              "      <th>business_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'funny': 0, 'useful': 5, 'cool': 2}</td>\n",
              "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
              "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
              "      <td>5</td>\n",
              "      <td>2011-01-26</td>\n",
              "      <td>My wife took me here on my birthday for breakf...</td>\n",
              "      <td>review</td>\n",
              "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'funny': 0, 'useful': 0, 'cool': 0}</td>\n",
              "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
              "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
              "      <td>5</td>\n",
              "      <td>2011-07-27</td>\n",
              "      <td>I have no idea why some people give bad review...</td>\n",
              "      <td>review</td>\n",
              "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'funny': 0, 'useful': 1, 'cool': 0}</td>\n",
              "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
              "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
              "      <td>4</td>\n",
              "      <td>2012-06-14</td>\n",
              "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
              "      <td>review</td>\n",
              "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'funny': 0, 'useful': 2, 'cool': 1}</td>\n",
              "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
              "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
              "      <td>5</td>\n",
              "      <td>2010-05-27</td>\n",
              "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
              "      <td>review</td>\n",
              "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{'funny': 0, 'useful': 0, 'cool': 0}</td>\n",
              "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
              "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
              "      <td>5</td>\n",
              "      <td>2012-01-05</td>\n",
              "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
              "      <td>review</td>\n",
              "      <td>6ozycU1RpktNG2-1BroVtw</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  votes  ...             business_id\n",
              "0  {'funny': 0, 'useful': 5, 'cool': 2}  ...  9yKzy9PApeiPPOUJEtnvkg\n",
              "1  {'funny': 0, 'useful': 0, 'cool': 0}  ...  ZRJwVLyzEJq1VAihDhYiow\n",
              "2  {'funny': 0, 'useful': 1, 'cool': 0}  ...  6oRAC4uyJCsJl1X0WZpVSA\n",
              "3  {'funny': 0, 'useful': 2, 'cool': 1}  ...  _1QQZuf4zZOyFCvXc0o6Vg\n",
              "4  {'funny': 0, 'useful': 0, 'cool': 0}  ...  6ozycU1RpktNG2-1BroVtw\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5RVb66H0bHV"
      },
      "source": [
        "data = data[data.stars != 3]\n",
        "data['sentiment'] = data['stars'] >= 4\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, data.sentiment, test_size=0.2)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4Zk8iku0f4u"
      },
      "source": [
        "pipeline = Pipeline([\n",
        "    ('vectorizer', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('classifier', LogisticRegression())\n",
        "])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCy5zWvd0lFu"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m21Ufzz10oWH",
        "outputId": "870af534-0f02-4676-99a8-7f1f71e9b368"
      },
      "source": [
        "scores = cross_val_score(pipeline, X_train.text, y_train, scoring='accuracy', cv=5, n_jobs=-1)\n",
        "\n",
        "mean = scores.mean()\n",
        "std = scores.std()\n",
        "print(mean)\n",
        "print(std)\n",
        "\n",
        "print(pipeline.get_params())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9404054357952903\n",
            "0.00156373658254123\n",
            "{'memory': None, 'steps': [('vectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
            "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
            "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
            "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
            "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
            "                tokenizer=None, vocabulary=None)), ('tfidf', TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)), ('classifier', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False))], 'verbose': False, 'vectorizer': CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
            "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
            "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
            "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
            "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
            "                tokenizer=None, vocabulary=None), 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), 'classifier': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False), 'vectorizer__analyzer': 'word', 'vectorizer__binary': False, 'vectorizer__decode_error': 'strict', 'vectorizer__dtype': <class 'numpy.int64'>, 'vectorizer__encoding': 'utf-8', 'vectorizer__input': 'content', 'vectorizer__lowercase': True, 'vectorizer__max_df': 1.0, 'vectorizer__max_features': None, 'vectorizer__min_df': 1, 'vectorizer__ngram_range': (1, 1), 'vectorizer__preprocessor': None, 'vectorizer__stop_words': None, 'vectorizer__strip_accents': None, 'vectorizer__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'vectorizer__tokenizer': None, 'vectorizer__vocabulary': None, 'tfidf__norm': 'l2', 'tfidf__smooth_idf': True, 'tfidf__sublinear_tf': False, 'tfidf__use_idf': True, 'classifier__C': 1.0, 'classifier__class_weight': None, 'classifier__dual': False, 'classifier__fit_intercept': True, 'classifier__intercept_scaling': 1, 'classifier__l1_ratio': None, 'classifier__max_iter': 100, 'classifier__multi_class': 'auto', 'classifier__n_jobs': None, 'classifier__penalty': 'l2', 'classifier__random_state': None, 'classifier__solver': 'lbfgs', 'classifier__tol': 0.0001, 'classifier__verbose': 0, 'classifier__warm_start': False}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCkqMqu61VSz"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "grid = {\n",
        "    'vectorizer__ngram_range': [(1, 1), (2, 1)],\n",
        "    'vectorizer__stop_words': [None, 'english'],\n",
        "    'classifier__penalty': ['l1', 'l2'],\n",
        "    'classifier__C': [1.0, 0.8],\n",
        "    'classifier__class_weight': [None, 'balanced'],\n",
        "    'classifier__n_jobs': [-1]\n",
        "}"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9Z09klv1dTy",
        "outputId": "d4dafae4-4d11-45ef-cf83-ca364dc40848"
      },
      "source": [
        "grid_search = GridSearchCV(pipeline, param_grid=grid, scoring='accuracy', n_jobs=-1, cv=5)\n",
        "grid_search.fit(X=X_train.text, y=y_train)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('vectorizer',\n",
              "                                        CountVectorizer(analyzer='word',\n",
              "                                                        binary=False,\n",
              "                                                        decode_error='strict',\n",
              "                                                        dtype=<class 'numpy.int64'>,\n",
              "                                                        encoding='utf-8',\n",
              "                                                        input='content',\n",
              "                                                        lowercase=True,\n",
              "                                                        max_df=1.0,\n",
              "                                                        max_features=None,\n",
              "                                                        min_df=1,\n",
              "                                                        ngram_range=(1, 1),\n",
              "                                                        preprocessor=None,\n",
              "                                                        stop_words=None,\n",
              "                                                        strip_accents=None,\n",
              "                                                        token_pattern...\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'classifier__C': [1.0, 0.8],\n",
              "                         'classifier__class_weight': [None, 'balanced'],\n",
              "                         'classifier__n_jobs': [-1],\n",
              "                         'classifier__penalty': ['l1', 'l2'],\n",
              "                         'vectorizer__ngram_range': [(1, 1), (2, 1)],\n",
              "                         'vectorizer__stop_words': [None, 'english']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xye4EmBT1g5X",
        "outputId": "77dc21c7-c29f-45d3-f706-1bae7acfbb4b"
      },
      "source": [
        "print(\"-----------\")\n",
        "print(grid_search.best_score_)\n",
        "print(grid_search.best_params_)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------\n",
            "0.9404054357952903\n",
            "{'classifier__C': 1.0, 'classifier__class_weight': None, 'classifier__n_jobs': -1, 'classifier__penalty': 'l2', 'vectorizer__ngram_range': (1, 1), 'vectorizer__stop_words': None}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fhv_pOr1oi6",
        "outputId": "7e22e42c-a344-4fe4-a84a-6f4d87feb27d"
      },
      "source": [
        "model = pipeline.fit(X_train.text, y_train)\n",
        "predicted = model.predict(X_test.text)\n",
        "print(\"model1: \" + str(np.mean(predicted == y_test)))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model1: 0.9419671541288648\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFrGjgw--X-c"
      },
      "source": [
        "pipeline2 = Pipeline([\n",
        "    ('vectorizer', CountVectorizer(min_df=1)),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('classifier', LogisticRegression(C=1.0, penalty='l1', solver='liblinear',class_weight=None, n_jobs=-1))\n",
        "    #('classifier', LogisticRegression(C=1.0, class_weight=None, n_jobs=-1, penalty='l1'))\n",
        "])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sj5DE1gQ99qy",
        "outputId": "b04b6b55-63b1-4a9c-879d-8df1ab0e9517"
      },
      "source": [
        "model2 = pipeline2.fit(X_train.text, y_train)\n",
        "predicted2 = model2.predict(X_test.text)\n",
        "print(\"model2: \" + str(np.mean(predicted2 == y_test)))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model2: 0.9431751008764039\n"
          ]
        }
      ]
    }
  ]
}