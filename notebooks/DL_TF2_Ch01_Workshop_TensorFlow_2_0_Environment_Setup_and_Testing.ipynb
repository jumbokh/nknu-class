{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "DL_TF2-Ch01-Workshop-TensorFlow 2.0 Environment Setup and Testing.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jumbokh/nknu-class/blob/main/notebooks/DL_TF2_Ch01_Workshop_TensorFlow_2_0_Environment_Setup_and_Testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Av2xjQxkbbhG"
      },
      "source": [
        "# Ch 1. Workshop - TensorFlow 2.0 Environment Setup & Testing\n",
        "\n",
        "2020/02/04\n",
        "\n",
        "--------------------------------------\n",
        "### **<< `Installation of TF 2.0 with Anaconda3` >>**\n",
        "+ ####  First, install `Anaconda 2019.10 for Windows/macOS/Linux` with `Python 3.7 version` https://www.anaconda.com/distribution/\n",
        "\n",
        "+ #### Next, run `TensorFlow 2.0 (for CPU)` Setup on `Anaconda Powershell Prompt` or `Anaconda Prompt` :\n",
        "> ####           `conda install tensorflow`\n",
        "--------------------------------------\n",
        "\n",
        "### [ Reference ]:\n",
        "+ TensorFlow.org, **\"Install TensorFlow 2\"** https://www.tensorflow.org/install\n",
        "+ 海萨, **\"Anaconda 安装tensorflow 2.0 报错解决办法\"** https://zhuanlan.zhihu.com/p/62031082\n",
        "+ TensorFlow.org, **\"Get Started with TensorFlow\"** https://www.tensorflow.org/tutorials/#get-started-with-tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CS7zQP7LbbhK"
      },
      "source": [
        "## [ Content ]\n",
        "- [1. Testing TF 2.0](#TF2)\n",
        "- [2. How to run TensorFlow 1.x code on TF 2.0](#RunTF1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rONZU5YXbbhL"
      },
      "source": [
        "<a id='TF2'></a>\n",
        "## 1. Testing TF 2.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQ0qpNKybbhM",
        "outputId": "8b47e88a-d21e-44e1-8eae-1e0cf586896e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "br19OGOzbbhO",
        "outputId": "2cdac81c-056b-4e44-d29d-d0764ff6a772",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# ---------------------------------------------\n",
        "# The following code is adopted from \n",
        "# Tutorial document of TensorFlow.org \n",
        "# for testing TensorFlow 2.0 setup: \n",
        "#\n",
        "# \"Get Started with TensorFlow\" \n",
        "#  https://www.tensorflow.org/tutorials/#get-started-with-tensorflow\n",
        "# ---------------------------------------------\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "model.evaluate(x_test, y_test, verbose=0) # verbose: Verbosity mode. 0=silent, 1=progress bar."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2215 - accuracy: 0.9349\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0969 - accuracy: 0.9701\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0691 - accuracy: 0.9775\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0526 - accuracy: 0.9828\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0416 - accuracy: 0.9865\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07281878590583801, 0.9778000116348267]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPEzhfZHbbhP"
      },
      "source": [
        "------------------------------\n",
        "<a id='RunTF1'></a>\n",
        "## 2. How to run TensorFlow 1.x code on TF 2.0\n",
        "+ ### It is still possible to run 1.X code, unmodified (except for contrib), in TensorFlow 2.0:\n",
        "\n",
        "> ####  **`import tensorflow.compat.v1 as tf`**  \n",
        "> ####  **`tf.disable_v2_behavior()`**\n",
        "\n",
        "> **[ NOTE ]:**\n",
        "+ **More detailed information regarding \"`Migrate your TensorFlow 1 code to TensorFlow 2`\" can be found here:** https://www.tensorflow.org/guide/migrate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jNmLrCZbbhQ",
        "outputId": "3861d030-7425-4d83-8356-8b9f8d0da2e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcIojC_AbbhR"
      },
      "source": [
        "---------------------------------------------\n",
        "### The following code is adopted for testing TensorFlow 2.0 setup from the reference below: \n",
        "\n",
        "+ Tom Hope, Yehezkel S. Resheff, and Itay Lieder, \"**Learning TensorFlow : A Guide to Building Deep Learning Systems**,\" Chapter 2 & 4, O'Reilly, 2017. https://goo.gl/iEmehh\n",
        "+ Download the code from GitHub : https://github.com/gigwegbe/Learning-TensorFlow\n",
        "---------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IbNM0sEbbhS"
      },
      "source": [
        "### Loading the MNIST dataset (from TensorFlow 2.0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5S_xBx9bbhV"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QuQUdShbbhW",
        "outputId": "2da525a3-ee07-4169-dff7-b35599a4671b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "x_train = np.array([x_train[i].flatten() for i in range(len(x_train))])\n",
        "x_train.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8C-bwggFbbhW",
        "outputId": "6d7217b8-cc0c-49d3-e529-3b6f2da26a69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_test = np.array([x_test[i].flatten() for i in range(len(x_test))])\n",
        "x_test.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJPN69P4bbhX",
        "outputId": "3d6a544d-86b9-4dcf-82cc-70655aca0c11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_train[0], y_test[0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vyjzk_CBbbhZ"
      },
      "source": [
        "def one_hot(vec, vals=10):\n",
        "    n = len(vec)\n",
        "    out = np.zeros((n, vals))\n",
        "    out[range(n), vec] = 1\n",
        "    return out"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oV3W8wZbbhZ",
        "outputId": "e095ca37-e718-42fa-b8b3-ba5e5fd62447",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_train = one_hot(y_train)\n",
        "y_train[0]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZvXCcvxbbha",
        "outputId": "7bec05e6-9002-41ff-bab1-ab8029e46807",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_test = one_hot(y_test)\n",
        "y_test[0]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldJxFrv1bbhb"
      },
      "source": [
        "### Building a Computation Graph on TF 1.x"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxbbKBgebbhb"
      },
      "source": [
        "# Each Input Image, X, with 28*28 (= 784) pixels\n",
        "X = tf.placeholder(tf.float32, [None, 784])\n",
        "\n",
        "# y_true : the training labeled dataset \n",
        "y_true = tf.placeholder(tf.float32,[None, 10])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8Qhq0Fpbbhc"
      },
      "source": [
        "# Initializing Weights & Biases for Nodes in All Hidden Layers \n",
        "def weight_variable(shape):\n",
        "    initial = tf.truncated_normal(shape, stddev=0.1) \n",
        "    return tf.Variable(initial)\n",
        "\n",
        "def bias_variable(shape):\n",
        "    initial = tf.constant(0.1, shape=shape) \n",
        "    return tf.Variable(initial)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooOqK3Iybbhd"
      },
      "source": [
        "# Building a Fully-Connected Deep Network\n",
        "def full_layer(inputs, size):\n",
        "    in_size = int(inputs.get_shape()[1]) \n",
        "    W = weight_variable([in_size, size]) \n",
        "    b = bias_variable([size])\n",
        "    return tf.add(tf.matmul(inputs, W), b)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZiibG6ybbhd",
        "outputId": "bc32dbfb-e43d-483e-e4ab-1b5b23e0af3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "keep_prob = tf.placeholder(tf.float32)  \n",
        "\n",
        "# < Hidden Layer 1 >\n",
        "layer_1_drop = tf.nn.dropout(X, keep_prob=keep_prob)\n",
        "#   Activation Function : ReLU\n",
        "layer_1_Outputs = tf.nn.relu(full_layer(layer_1_drop, 256))\n",
        "\n",
        "# < Hidden Layer 2 >\n",
        "layer_2_drop = tf.nn.dropout(layer_1_Outputs, keep_prob=keep_prob)\n",
        "#   Activation Function : ReLU\n",
        "layer_2_Outputs = tf.nn.relu(full_layer(layer_2_drop, 128))  \n",
        "\n",
        "# < Output Layer >\n",
        "output_drop = tf.nn.dropout(layer_2_Outputs, keep_prob=keep_prob)\n",
        "# Without Activation Function\n",
        "y_pred = full_layer(output_drop, 10)  "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6vImMvpbbhf",
        "outputId": "519eb004-6252-4047-8276-55870c4a35fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_pred, labels=y_true))\n",
        "gd_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
        "\n",
        "correct_mask = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y_true, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_mask, tf.float32))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yf5zZF_xbbhf"
      },
      "source": [
        "### Launching the Computation Graph on TF 1.x"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfnT6t5Ibbhg"
      },
      "source": [
        "def next_batch(i, images, labels, batch_size):\n",
        "    i_start = (i * batch_size) % len(images)\n",
        "    x, y = images[i_start : i_start+batch_size], labels[i_start : i_start+batch_size]\n",
        "    return x, y"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuQ9Oi-gbbhg",
        "outputId": "857dffb5-a459-4523-ec42-bbf2ea0902c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "NUM_STEPS = 8000\n",
        "MINIBATCH_SIZE = 100\n",
        "Display_Step = 1000\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    \n",
        "    for i in range(NUM_STEPS):\n",
        "        batch_xs, batch_ys = next_batch(i, x_train, y_train, MINIBATCH_SIZE)\n",
        "        sess.run(gd_step, feed_dict ={X: batch_xs, \n",
        "                                      y_true: batch_ys,\n",
        "                                      keep_prob: 0.5})\n",
        "        \n",
        "        if (i+1) % Display_Step == 0:\n",
        "            # Calculate batch loss and accuracy\n",
        "            loss_temp, accu_temp = sess.run([cross_entropy, accuracy], \n",
        "                                            feed_dict={X: batch_xs, \n",
        "                                                       y_true: batch_ys,\n",
        "                                                       keep_prob: 1.0})\n",
        "            print(\"Step \" + str(i+1).rjust(4) + \\\n",
        "                  \" : Loss = \" + \"{:.4f}\".format(loss_temp) + \\\n",
        "                  \", Accuracy = \" + \"{:.3f}\".format(accu_temp))\n",
        "\n",
        "    print(\"\\n Computing the test accuracy ... \", end = \" \")\n",
        "    \n",
        "    ##  ------------------------------------------------------------------\n",
        "    ##  Split the test procedure into 10 blocks of 1,000 images each. \n",
        "    ##  Doing this is important mostly for much larger datasets.\n",
        "    ##  ------------------------------------------------------------------\n",
        "    ##  mnist.test.images.shape : (10000, 784)\n",
        "    X_test = x_test.reshape(10, 1000, 784) \n",
        "    ##  mnist.test.labels.shape : (10000, 10)\n",
        "    Y_test = y_test.reshape(10, 1000, 10)   \n",
        "    \n",
        "    test_loss = np.mean([sess.run(cross_entropy,\n",
        "                                  feed_dict={X: X_test[i], \n",
        "                                             y_true: Y_test[i], \n",
        "                                             keep_prob: 1.0}) \n",
        "                                  for i in range(10)])\n",
        "    test_accu = np.mean([sess.run(accuracy,\n",
        "                                  feed_dict={X: X_test[i], \n",
        "                                             y_true: Y_test[i], \n",
        "                                             keep_prob: 1.0}) \n",
        "                                  for i in range(10)])\n",
        "    print(\"\\n [ Test  Accuracy ] : {}\".format(test_accu) +\n",
        "      \"\\n [ Test Loss Score ] : {}\".format(test_loss))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1000 : Loss = 0.1701, Accuracy = 0.970\n",
            "Step 2000 : Loss = 0.1124, Accuracy = 0.980\n",
            "Step 3000 : Loss = 0.0968, Accuracy = 0.990\n",
            "Step 4000 : Loss = 0.0757, Accuracy = 0.980\n",
            "Step 5000 : Loss = 0.0570, Accuracy = 0.990\n",
            "Step 6000 : Loss = 0.0965, Accuracy = 0.990\n",
            "Step 7000 : Loss = 0.0690, Accuracy = 0.980\n",
            "Step 8000 : Loss = 0.0362, Accuracy = 1.000\n",
            "\n",
            " Computing the test accuracy ...  \n",
            " [ Test  Accuracy ] : 0.9647000432014465\n",
            " [ Test Loss Score ] : 0.12234125286340714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiIcvPs8bbhh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}