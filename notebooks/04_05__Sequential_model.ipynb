{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "04_05_ Sequential_model.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jumbokh/nknu-class/blob/main/notebooks/04_05__Sequential_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRO1an9bpyEe"
      },
      "source": [
        "# Sequential model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jzg6OCUKpyEj"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPheu1PDpyEl"
      },
      "source": [
        "## 建立模型結構"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQtYw7OFpyEm"
      },
      "source": [
        "## 模型語法 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82MhOoCSpyEn"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOv7TAb1pyEo"
      },
      "source": [
        "## 模型語法 2：將input_shape拿掉，以model參數設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7a7dHLApyEp"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "x = tf.keras.layers.Input(shape=(28, 28))\n",
        "# 或 x = tf.Variable(tf.random.truncated_normal([28, 28]))\n",
        "y = model(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hK-unmtxpyEs"
      },
      "source": [
        "## 模型語法 3：可以直接串連神經層"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSzOyOxxpyEu"
      },
      "source": [
        "layer1 = tf.keras.layers.Dense(2, activation=\"relu\", name=\"layer1\")\n",
        "layer2 = tf.keras.layers.Dense(3, activation=\"relu\", name=\"layer2\")\n",
        "layer3 = tf.keras.layers.Dense(4, name=\"layer3\")\n",
        "\n",
        "# Call layers on a test input\n",
        "x = tf.ones((3, 3))\n",
        "y = layer3(layer2(layer1(x)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNqIgTwQpyEw"
      },
      "source": [
        "## 臨時加減神經層"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q92lGR6GpyEx",
        "outputId": "b68830ad-f8dc-432e-a697-2e58e0250073"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# 刪減一層\n",
        "model.pop()\n",
        "print(f'神經層數: {len(model.layers)}')\n",
        "model.layers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "神經層數: 3\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[<tensorflow.python.keras.layers.core.Flatten at 0x18336491910>,\n",
              " <tensorflow.python.keras.layers.core.Dense at 0x18270b652e0>,\n",
              " <tensorflow.python.keras.layers.core.Dropout at 0x18276ff08b0>]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "6yLkrRAnpyEy",
        "outputId": "b50b3dc7-fad5-418f-8d8f-34baf1ea69b5"
      },
      "source": [
        "# 增加一層\n",
        "model.add(tf.keras.layers.Dense(10))\n",
        "print(f'神經層數: {len(model.layers)}')\n",
        "model.layers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "神經層數: 4\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[<tensorflow.python.keras.layers.core.Flatten at 0x18336491910>,\n",
              " <tensorflow.python.keras.layers.core.Dense at 0x18270b652e0>,\n",
              " <tensorflow.python.keras.layers.core.Dropout at 0x18276ff08b0>,\n",
              " <tensorflow.python.keras.layers.core.Dense at 0x18252b4cfd0>]"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6upERgxYpyEz"
      },
      "source": [
        "## 取得模型及神經層資訊"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XfL6LxcpyEz",
        "outputId": "c2b7f575-b911-49a8-b809-8372f605a78c"
      },
      "source": [
        "# 建立 3 layers\n",
        "layer1 = tf.keras.layers.Dense(2, activation=\"relu\", name=\"layer1\", \n",
        "                               input_shape=(28, 28))\n",
        "layer2 = tf.keras.layers.Dense(3, activation=\"relu\", name=\"layer2\")\n",
        "layer3 = tf.keras.layers.Dense(4, name=\"layer3\")\n",
        "\n",
        "# 建立模型\n",
        "model = tf.keras.models.Sequential([\n",
        "  layer1,\n",
        "  layer2,\n",
        "  layer3\n",
        "])\n",
        "\n",
        "# 讀取模型權重\n",
        "print(f'神經層參數類別總數: {len(model.weights)}')\n",
        "model.weights"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "神經層參數類別總數: 6\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[<tf.Variable 'layer1/kernel:0' shape=(28, 2) dtype=float32, numpy=\n",
              " array([[-0.40281397,  0.2205016 ],\n",
              "        [-0.03376389,  0.15561956],\n",
              "        [ 0.4151038 ,  0.02849016],\n",
              "        [-0.15993604,  0.03800485],\n",
              "        [ 0.06474555,  0.39933097],\n",
              "        [ 0.41804487, -0.35671836],\n",
              "        [-0.09304568, -0.12987521],\n",
              "        [-0.07738718,  0.4214089 ],\n",
              "        [-0.03624141, -0.15986142],\n",
              "        [ 0.41953433, -0.14494684],\n",
              "        [-0.16713199, -0.36726573],\n",
              "        [ 0.28147936, -0.07306954],\n",
              "        [ 0.06702495,  0.29314017],\n",
              "        [-0.4076838 , -0.22369348],\n",
              "        [ 0.35500747, -0.20532322],\n",
              "        [-0.4465798 , -0.44517472],\n",
              "        [-0.03784758,  0.18521959],\n",
              "        [-0.32220033, -0.2665765 ],\n",
              "        [-0.02831304, -0.01577556],\n",
              "        [ 0.39644188, -0.16043621],\n",
              "        [ 0.32985735,  0.40040267],\n",
              "        [ 0.440423  , -0.3224007 ],\n",
              "        [ 0.08332956, -0.33867747],\n",
              "        [-0.14314255,  0.11406481],\n",
              "        [-0.4151996 ,  0.03236541],\n",
              "        [ 0.16692811,  0.4445855 ],\n",
              "        [-0.28081325, -0.15366495],\n",
              "        [-0.08408925, -0.07401264]], dtype=float32)>,\n",
              " <tf.Variable 'layer1/bias:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>,\n",
              " <tf.Variable 'layer2/kernel:0' shape=(2, 3) dtype=float32, numpy=\n",
              " array([[-0.85765153, -0.52234036,  0.6214608 ],\n",
              "        [ 0.39134014,  0.85754156, -0.3411767 ]], dtype=float32)>,\n",
              " <tf.Variable 'layer2/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>,\n",
              " <tf.Variable 'layer3/kernel:0' shape=(3, 4) dtype=float32, numpy=\n",
              " array([[ 0.69865596,  0.38489008, -0.72880864, -0.13361835],\n",
              "        [ 0.27738178, -0.41328734,  0.6602769 , -0.44029424],\n",
              "        [ 0.11844432,  0.45066047,  0.516515  , -0.5549101 ]],\n",
              "       dtype=float32)>,\n",
              " <tf.Variable 'layer3/bias:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>]"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kutXzT3MpyE0",
        "outputId": "1e691425-ee6a-4560-a238-d715a5022586"
      },
      "source": [
        "print(f'{layer2.name}: {layer2.weights}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "layer2: [<tf.Variable 'layer2/kernel:0' shape=(2, 3) dtype=float32, numpy=\n",
            "array([[-0.85765153, -0.52234036,  0.6214608 ],\n",
            "       [ 0.39134014,  0.85754156, -0.3411767 ]], dtype=float32)>, <tf.Variable 'layer2/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "_sEluhk_pyE0",
        "outputId": "1d61d8aa-134b-4bd0-cbb0-4ff7f53356ce"
      },
      "source": [
        "# 取得模型彙總資訊\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_24\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "layer1 (Dense)               (None, 28, 2)             58        \n",
            "_________________________________________________________________\n",
            "layer2 (Dense)               (None, 28, 3)             9         \n",
            "_________________________________________________________________\n",
            "layer3 (Dense)               (None, 28, 4)             16        \n",
            "_________________________________________________________________\n",
            "layer4 (Dense)               (None, 28, 5)             25        \n",
            "=================================================================\n",
            "Total params: 108\n",
            "Trainable params: 108\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsYOrRaQpyE1"
      },
      "source": [
        "## 一邊加神經層，一邊顯示模型彙總資訊，以利除錯"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "1M1pJsPCpyE1",
        "outputId": "3762d8e9-c78a-45eb-87ba-10b88a9241c9"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.Input(shape=(250, 250, 3)))  # 250x250 RGB images\n",
        "model.add(layers.Conv2D(32, 5, strides=2, activation=\"relu\"))\n",
        "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
        "model.add(layers.MaxPooling2D(3))\n",
        "\n",
        "# 顯示目前模型彙總資訊\n",
        "model.summary()\n",
        "\n",
        "# The answer was: (40, 40, 32), so we can keep downsampling...\n",
        "\n",
        "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
        "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
        "model.add(layers.MaxPooling2D(3))\n",
        "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
        "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
        "model.add(layers.MaxPooling2D(2))\n",
        "\n",
        "# 顯示目前模型彙總資訊\n",
        "model.summary()\n",
        "\n",
        "# Now that we have 4x4 feature maps, time to apply global max pooling.\n",
        "model.add(layers.GlobalMaxPooling2D())\n",
        "\n",
        "# Finally, we add a classification layer.\n",
        "model.add(layers.Dense(10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_26\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 123, 123, 32)      2432      \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 121, 121, 32)      9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 40, 40, 32)        0         \n",
            "=================================================================\n",
            "Total params: 11,680\n",
            "Trainable params: 11,680\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_26\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 123, 123, 32)      2432      \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 121, 121, 32)      9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 40, 40, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 38, 38, 32)        9248      \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 36, 36, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 10, 10, 32)        9248      \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 8, 8, 32)          9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 32)          0         \n",
            "=================================================================\n",
            "Total params: 48,672\n",
            "Trainable params: 48,672\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLrepp5ipyE2"
      },
      "source": [
        "## 取得每一層神經層的output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7q0ZbOtLpyE2",
        "outputId": "817b310b-e4a7-4373-b499-7fcfad7cdc5f"
      },
      "source": [
        "# 設定模型\n",
        "initial_model = tf.keras.Sequential(\n",
        "    [\n",
        "        tf.keras.Input(shape=(250, 250, 3)),\n",
        "        layers.Conv2D(32, 5, strides=2, activation=\"relu\"),\n",
        "        layers.Conv2D(32, 3, activation=\"relu\"),\n",
        "        layers.Conv2D(32, 3, activation=\"relu\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 設定模型的 input/output\n",
        "feature_extractor = tf.keras.Model(\n",
        "    inputs=initial_model.inputs,\n",
        "    outputs=[layer.output for layer in initial_model.layers],\n",
        ")\n",
        "\n",
        "# 呼叫 feature_extractor 取得 output\n",
        "x = tf.ones((1, 250, 250, 3))\n",
        "features = feature_extractor(x)\n",
        "features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(1, 123, 123, 32), dtype=float32, numpy=\n",
              " array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
              "          [0., 0., 0., ..., 0., 0., 0.],\n",
              "          [0., 0., 0., ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0., ..., 0., 0., 0.],\n",
              "          [0., 0., 0., ..., 0., 0., 0.],\n",
              "          [0., 0., 0., ..., 0., 0., 0.]],\n",
              " \n",
              "         [[0., 0., 0., ..., 0., 0., 0.],\n",
              "          [0., 0., 0., ..., 0., 0., 0.],\n",
              "          [0., 0., 0., ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0., ..., 0., 0., 0.],\n",
              "          [0., 0., 0., ..., 0., 0., 0.],\n",
              "          [0., 0., 0., ..., 0., 0., 0.]],\n",
              " \n",
              "         [[0., 0., 0., ..., 0., 0., 0.],\n",
              "          [0., 0., 0., ..., 0., 0., 0.],\n",
              "          [0., 0., 0., ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0., ..., 0., 0., 0.],\n",
              "          [0., 0., 0., ..., 0., 0., 0.],\n",
              "          [0., 0., 0., ..., 0., 0., 0.]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[0., 0., 0., ..., 0., 0., 0.],\n",
              "          [0., 0., 0., ..., 0., 0., 0.],\n",
              "          [0., 0., 0., ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0., ..., 0., 0., 0.],\n",
              "          [0., 0., 0., ..., 0., 0., 0.],\n",
              "          [0., 0., 0., ..., 0., 0., 0.]],\n",
              " \n",
              "         [[0., 0., 0., ..., 0., 0., 0.],\n",
              "          [0., 0., 0., ..., 0., 0., 0.],\n",
              "          [0., 0., 0., ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0., ..., 0., 0., 0.],\n",
              "          [0., 0., 0., ..., 0., 0., 0.],\n",
              "          [0., 0., 0., ..., 0., 0., 0.]],\n",
              " \n",
              "         [[0., 0., 0., ..., 0., 0., 0.],\n",
              "          [0., 0., 0., ..., 0., 0., 0.],\n",
              "          [0., 0., 0., ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0., ..., 0., 0., 0.],\n",
              "          [0., 0., 0., ..., 0., 0., 0.],\n",
              "          [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(1, 121, 121, 32), dtype=float32, numpy=\n",
              " array([[[[0.08905184, 0.        , 0.        , ..., 0.        ,\n",
              "           0.42522174, 0.        ],\n",
              "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
              "           0.42522174, 0.        ],\n",
              "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
              "           0.42522174, 0.        ],\n",
              "          ...,\n",
              "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
              "           0.42522174, 0.        ],\n",
              "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
              "           0.42522174, 0.        ],\n",
              "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
              "           0.42522174, 0.        ]],\n",
              " \n",
              "         [[0.08905184, 0.        , 0.        , ..., 0.        ,\n",
              "           0.42522174, 0.        ],\n",
              "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
              "           0.42522174, 0.        ],\n",
              "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
              "           0.42522174, 0.        ],\n",
              "          ...,\n",
              "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
              "           0.42522174, 0.        ],\n",
              "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
              "           0.42522174, 0.        ],\n",
              "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
              "           0.42522174, 0.        ]],\n",
              " \n",
              "         [[0.08905184, 0.        , 0.        , ..., 0.        ,\n",
              "           0.42522174, 0.        ],\n",
              "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
              "           0.42522174, 0.        ],\n",
              "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
              "           0.42522174, 0.        ],\n",
              "          ...,\n",
              "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
              "           0.42522174, 0.        ],\n",
              "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
              "           0.42522174, 0.        ],\n",
              "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
              "           0.42522174, 0.        ]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[0.08905184, 0.        , 0.        , ..., 0.        ,\n",
              "           0.42522174, 0.        ],\n",
              "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
              "           0.42522174, 0.        ],\n",
              "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
              "           0.42522174, 0.        ],\n",
              "          ...,\n",
              "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
              "           0.42522174, 0.        ],\n",
              "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
              "           0.42522174, 0.        ],\n",
              "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
              "           0.42522174, 0.        ]],\n",
              " \n",
              "         [[0.08905184, 0.        , 0.        , ..., 0.        ,\n",
              "           0.42522174, 0.        ],\n",
              "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
              "           0.42522174, 0.        ],\n",
              "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
              "           0.42522174, 0.        ],\n",
              "          ...,\n",
              "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
              "           0.42522174, 0.        ],\n",
              "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
              "           0.42522174, 0.        ],\n",
              "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
              "           0.42522174, 0.        ]],\n",
              " \n",
              "         [[0.08905184, 0.        , 0.        , ..., 0.        ,\n",
              "           0.42522174, 0.        ],\n",
              "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
              "           0.42522174, 0.        ],\n",
              "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
              "           0.42522174, 0.        ],\n",
              "          ...,\n",
              "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
              "           0.42522174, 0.        ],\n",
              "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
              "           0.42522174, 0.        ],\n",
              "          [0.08905184, 0.        , 0.        , ..., 0.        ,\n",
              "           0.42522174, 0.        ]]]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(1, 119, 119, 32), dtype=float32, numpy=\n",
              " array([[[[0.25353807, 0.        , 0.        , ..., 0.        ,\n",
              "           0.        , 0.05385849],\n",
              "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
              "           0.        , 0.05385849],\n",
              "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
              "           0.        , 0.05385849],\n",
              "          ...,\n",
              "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
              "           0.        , 0.05385849],\n",
              "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
              "           0.        , 0.05385849],\n",
              "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
              "           0.        , 0.05385849]],\n",
              " \n",
              "         [[0.25353807, 0.        , 0.        , ..., 0.        ,\n",
              "           0.        , 0.05385849],\n",
              "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
              "           0.        , 0.05385849],\n",
              "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
              "           0.        , 0.05385849],\n",
              "          ...,\n",
              "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
              "           0.        , 0.05385849],\n",
              "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
              "           0.        , 0.05385849],\n",
              "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
              "           0.        , 0.05385849]],\n",
              " \n",
              "         [[0.25353807, 0.        , 0.        , ..., 0.        ,\n",
              "           0.        , 0.05385849],\n",
              "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
              "           0.        , 0.05385849],\n",
              "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
              "           0.        , 0.05385849],\n",
              "          ...,\n",
              "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
              "           0.        , 0.05385849],\n",
              "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
              "           0.        , 0.05385849],\n",
              "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
              "           0.        , 0.05385849]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[0.25353807, 0.        , 0.        , ..., 0.        ,\n",
              "           0.        , 0.05385849],\n",
              "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
              "           0.        , 0.05385849],\n",
              "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
              "           0.        , 0.05385849],\n",
              "          ...,\n",
              "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
              "           0.        , 0.05385849],\n",
              "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
              "           0.        , 0.05385849],\n",
              "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
              "           0.        , 0.05385849]],\n",
              " \n",
              "         [[0.25353807, 0.        , 0.        , ..., 0.        ,\n",
              "           0.        , 0.05385849],\n",
              "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
              "           0.        , 0.05385849],\n",
              "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
              "           0.        , 0.05385849],\n",
              "          ...,\n",
              "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
              "           0.        , 0.05385849],\n",
              "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
              "           0.        , 0.05385849],\n",
              "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
              "           0.        , 0.05385849]],\n",
              " \n",
              "         [[0.25353807, 0.        , 0.        , ..., 0.        ,\n",
              "           0.        , 0.05385849],\n",
              "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
              "           0.        , 0.05385849],\n",
              "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
              "           0.        , 0.05385849],\n",
              "          ...,\n",
              "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
              "           0.        , 0.05385849],\n",
              "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
              "           0.        , 0.05385849],\n",
              "          [0.25353807, 0.        , 0.        , ..., 0.        ,\n",
              "           0.        , 0.05385849]]]], dtype=float32)>]"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6TUyAXApyE2",
        "outputId": "0d612545-f0ba-409c-d2a5-623f981b9ef0"
      },
      "source": [
        "# 設定模型\n",
        "initial_model = tf.keras.Sequential(\n",
        "    [\n",
        "        tf.keras.Input(shape=(250, 250, 3)),\n",
        "        layers.Conv2D(32, 5, strides=2, activation=\"relu\"),\n",
        "        layers.Conv2D(32, 3, activation=\"relu\", name=\"my_intermediate_layer\"),\n",
        "        layers.Conv2D(32, 3, activation=\"relu\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 設定模型的 input/output\n",
        "feature_extractor = tf.keras.Model(\n",
        "    inputs=initial_model.inputs,\n",
        "    outputs=initial_model.get_layer(name=\"my_intermediate_layer\").output,\n",
        ")\n",
        "\n",
        "# 呼叫 feature_extractor 取得 output\n",
        "x = tf.ones((1, 250, 250, 3))\n",
        "features = feature_extractor(x)\n",
        "features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 121, 121, 32), dtype=float32, numpy=\n",
              "array([[[[0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
              "          0.        , 0.        ],\n",
              "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
              "          0.        , 0.        ],\n",
              "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
              "          0.        , 0.        ],\n",
              "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
              "          0.        , 0.        ],\n",
              "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
              "          0.        , 0.        ]],\n",
              "\n",
              "        [[0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
              "          0.        , 0.        ],\n",
              "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
              "          0.        , 0.        ],\n",
              "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
              "          0.        , 0.        ],\n",
              "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
              "          0.        , 0.        ],\n",
              "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
              "          0.        , 0.        ]],\n",
              "\n",
              "        [[0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
              "          0.        , 0.        ],\n",
              "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
              "          0.        , 0.        ],\n",
              "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
              "          0.        , 0.        ],\n",
              "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
              "          0.        , 0.        ],\n",
              "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
              "          0.        , 0.        ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
              "          0.        , 0.        ],\n",
              "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
              "          0.        , 0.        ],\n",
              "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
              "          0.        , 0.        ],\n",
              "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
              "          0.        , 0.        ],\n",
              "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
              "          0.        , 0.        ]],\n",
              "\n",
              "        [[0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
              "          0.        , 0.        ],\n",
              "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
              "          0.        , 0.        ],\n",
              "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
              "          0.        , 0.        ],\n",
              "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
              "          0.        , 0.        ],\n",
              "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
              "          0.        , 0.        ]],\n",
              "\n",
              "        [[0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
              "          0.        , 0.        ],\n",
              "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
              "          0.        , 0.        ],\n",
              "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
              "          0.        , 0.        ],\n",
              "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
              "          0.        , 0.        ],\n",
              "         [0.        , 0.41995677, 0.32568812, ..., 0.27618825,\n",
              "          0.        , 0.        ]]]], dtype=float32)>"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFVJv5ewpyE3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}