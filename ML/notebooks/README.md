### [Notebooks](https://github.com/jumbokh/nknu-class/blob/main/ML/notebooks/Notebooks.md)
### Clustering 分群法
<pre>
目的是將相似的實例聚成一組。分群法很適合用於資料分析、顧客細分、推薦系統、
搜尋引擎、圖像分割、半監督學習、降維，及其他
</pre>
### anomaly detection 異常檢測
<pre>
目的是學習 "正常" 的資料長怎麼樣，接著用它來偵測不正常的實例。
</pre>
### density estimation 密度估計
<pre>
目的是估計產生資料集的隨機程序的機率密度函數(PDF)。
密度估計通常用於異常檢測：在密度很低的區域中的實例很有可能是異常的。
他也很適合用來分析資料與視覺化。
</pre>
### K-Means && K Nearest Neighber
<pre>
KNN就是讓你透過一群已經標記好類別的資料，來針對未分類的資料做分類的工具。

那如果只有一群尚未分類的資料，我們要怎麼將他分類呢？
</pre>
##
#### K-Means 運作流程
<pre>
1. 先決定K
2. k就是最後要分成幾群，如果你希望最後資料分成 3群 ，k就是3。
3. 在你的資料中，隨機選擇k個點做為群中心(也可以直接從資料挑)。
4. 把每一筆資料標記上離它最近的群中心
5. 根據同一個標記的所有資料，重新計算出群中心。
6. 如果步驟4算出來的群中心跟原本步驟3不同，則重複步驟3
</pre>
##
<pre>
1. 我們要分成兩群(K=2),所以一開始先挑了兩個點(b)。

2. 將資料標記(著色)成距離最近的群中心(c)。

3. 同一個群中心(顏色)的資料重新計算新的中心位置(d)。

4. 同步驟2，做標記(著色的動作)。

5. 同步驟3，重新計算新的群中心的位置(f)。

6. 再重複步驟2,3 結果群中心位置不變，表示分群完畢。
</pre>
##
#### Q&A
<pre>
K-means簡單快速的方法被廣泛的使用，但是實際運用上還是有一些問題需要被克服。正所謂萬事起頭難，K-means一開始會先要求你提供K，但是k到底要多少才合理？ 
</pre>
